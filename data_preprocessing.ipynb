{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8904bc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\andi1\\documents\\python stuff\\sentiment analysis (x or twitter)\\env\\lib\\site-packages (2.2.3)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.1 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035c747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     c:\\Users\\andi1\\Documents\\Python Stuff\\Sentiment\n",
      "[nltk_data]     Analysis (X or Twitter)\\env\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\andi1\\Documents\\Python Stuff\\Sentiment\n",
      "[nltk_data]     Analysis (X or Twitter)\\env\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857492ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./tweets_data.csv')\n",
    "df = df.dropna(subset=['content'])  # pastikan tidak ada tweet kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20615a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()                              # ubah jadi lowercase\n",
    "    text = re.sub(r'http\\S+', '', text)              # hapus URL\n",
    "    text = re.sub(r'@\\w+', '', text)                 # hapus mention\n",
    "    text = re.sub(r'#\\w+', '', text)                 # hapus hashtag\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)              # hapus tanda baca\n",
    "    text = re.sub(r'\\d+', '', text)                  # hapus angka\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)              # hapus spasi ganda\n",
    "    return text.strip()\n",
    "\n",
    "df['clean_text'] = df['content'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafdfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokens'] = df['clean_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0c5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('indonesian'))  # atau 'english' kalau tweet-nya campur\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47183a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  \\\n",
      "0  Lebih dari itu, masih banyak program lain yg s...   \n",
      "1  Rapat Dpr yg membahas anggaran pendidikan dila...   \n",
      "2  ini tu salah satu bukti ketololan pendidikan k...   \n",
      "3  Lagi2 dampak efisiensi anggaran pendidikan. Ba...   \n",
      "4  \"kesenjangan pendidikan\" dan kebijakan pemerin...   \n",
      "5  Anggaran pendidikan beneran dipangkas? Lomba F...   \n",
      "6  Ini poin kunci:\\nKontrol Keuangan: Pemerintah ...   \n",
      "7  Et dah anggaran pendidikan, kesehatan dan infr...   \n",
      "8  anggaran pendidikan 400 trilyun itu lu coba ma...   \n",
      "9  Anggaran pendidikan dan kesehatan bukan utama ...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  lebih dari itu masih banyak program lain yg se...   \n",
      "1  rapat dpr yg membahas anggaran pendidikan dila...   \n",
      "2  ini tu salah satu bukti ketololan pendidikan k...   \n",
      "3  lagi dampak efisiensi anggaran pendidikan baru...   \n",
      "4  kesenjangan pendidikan dan kebijakan pemerinta...   \n",
      "5  anggaran pendidikan beneran dipangkas lomba fl...   \n",
      "6  ini poin kunci\\nkontrol keuangan pemerintah me...   \n",
      "7  et dah anggaran pendidikan kesehatan dan infra...   \n",
      "8  anggaran pendidikan trilyun itu lu coba manfaa...   \n",
      "9  anggaran pendidikan dan kesehatan bukan utama ...   \n",
      "\n",
      "                                     filtered_tokens  \n",
      "0  [program, menimbulkan, efek, domino, ekonomi, ...  \n",
      "1  [rapat, dpr, membahas, anggaran, pendidikan, d...  \n",
      "2  [salah, bukti, ketololan, pendidikan, sampe, s...  \n",
      "3  [dampak, efisiensi, anggaran, pendidikan, buka...  \n",
      "4  [kesenjangan, pendidikan, kebijakan, pemerinta...  \n",
      "5  [anggaran, pendidikan, beneran, dipangkas, lom...  \n",
      "6  [poin, kunci, kontrol, keuangan, pemerintah, m...  \n",
      "7  [dah, anggaran, pendidikan, kesehatan, infrast...  \n",
      "8  [anggaran, pendidikan, trilyun, coba, manfaatk...  \n",
      "9  [anggaran, pendidikan, kesehatan, utama, utama...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['content', 'clean_text', 'filtered_tokens']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['username'] == '@grok') | (df['content'].str.contains(r'@grok', case=False, na=False)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb1bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
